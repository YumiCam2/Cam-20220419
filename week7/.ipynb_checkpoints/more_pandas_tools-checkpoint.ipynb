{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#More-pandas-Tools\" data-toc-modified-id=\"More-pandas-Tools-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>More <code>pandas</code> Tools</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-Goals\" data-toc-modified-id=\"Learning-Goals-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Learning Goals</a></span></li><li><span><a href=\"#Mapping\" data-toc-modified-id=\"Mapping-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series.map()\" data-toc-modified-id=\"Series.map()-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span><code>Series.map()</code></a></span></li><li><span><a href=\"#More-Sophisticated-Mapping\" data-toc-modified-id=\"More-Sophisticated-Mapping-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>More Sophisticated Mapping</a></span></li><li><span><a href=\"#Lambda-Functions\" data-toc-modified-id=\"Lambda-Functions-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Lambda Functions</a></span></li></ul></li><li><span><a href=\"#Handling-Missing-Data\" data-toc-modified-id=\"Handling-Missing-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Handling Missing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fill-with-a-Relevant-Value\" data-toc-modified-id=\"Fill-with-a-Relevant-Value-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Fill with a Relevant Value</a></span></li><li><span><a href=\"#Fill-with-a-Reasonable-Value\" data-toc-modified-id=\"Fill-with-a-Reasonable-Value-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Fill with a Reasonable Value</a></span></li><li><span><a href=\"#Specify-That-the-Data-Were-Missing\" data-toc-modified-id=\"Specify-That-the-Data-Were-Missing-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Specify That the Data Were Missing</a></span></li><li><span><a href=\"#Drop-Missing-Data\" data-toc-modified-id=\"Drop-Missing-Data-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Drop Missing Data</a></span></li><li><span><a href=\"#Comparing-Before-and-After\" data-toc-modified-id=\"Comparing-Before-and-After-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Comparing Before and After</a></span></li></ul></li><li><span><a href=\"#Aggregating-over-DataFrames:-.groupby()\" data-toc-modified-id=\"Aggregating-over-DataFrames:-.groupby()-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Aggregating over DataFrames: <code>.groupby()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#.groups-and-.get_group()\" data-toc-modified-id=\".groups-and-.get_group()-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span><code>.groups</code> and <code>.get_group()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Multi-Indexing\" data-toc-modified-id=\"Multi-Indexing-1.4.1.1\"><span class=\"toc-item-num\">1.4.1.1&nbsp;&nbsp;</span>Multi-Indexing</a></span></li></ul></li><li><span><a href=\"#Aggregating\" data-toc-modified-id=\"Aggregating-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Aggregating</a></span></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Pivoting-a-DataFrame\" data-toc-modified-id=\"Level-Up:-Pivoting-a-DataFrame-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Level Up: Pivoting a DataFrame</a></span><ul class=\"toc-item\"><li><span><a href=\"#.pivot_table()\" data-toc-modified-id=\".pivot_table()-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span><code>.pivot_table()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-1.5.1.1\"><span class=\"toc-item-num\">1.5.1.1&nbsp;&nbsp;</span>Example</a></span></li><li><span><a href=\"#Back-to-Austin-animals\" data-toc-modified-id=\"Back-to-Austin-animals-1.5.1.2\"><span class=\"toc-item-num\">1.5.1.2&nbsp;&nbsp;</span>Back to Austin animals</a></span></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Methods-for-Combining-DataFrames:-.join(),-.merge(),-pd.concat()\" data-toc-modified-id=\"Level-Up:-Methods-for-Combining-DataFrames:-.join(),-.merge(),-pd.concat()-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Level Up: Methods for Combining DataFrames: <code>.join()</code>, <code>.merge()</code>, <code>pd.concat()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#.join()\" data-toc-modified-id=\".join()-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span><code>.join()</code></a></span></li><li><span><a href=\"#The-how-Parameter\" data-toc-modified-id=\"The-how-Parameter-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>The <code>how</code> Parameter</a></span></li><li><span><a href=\"#pd.concat()\" data-toc-modified-id=\"pd.concat()-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span><code>pd.concat()</code></a></span></li></ul></li><li><span><a href=\"#King-County-Assessments\" data-toc-modified-id=\"King-County-Assessments-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>King County Assessments</a></span></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Exercises</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More `pandas` Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use mapping tools to transform data frame columns\n",
    "- Handle missing data\n",
    "- Use GroupBy objects to organize and aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll work with the Austin Animal Center dataset and with data from [King County's Department of Assessments (Seattle housing data)](https://info.kingcounty.gov/assessor/DataDownload/default.aspx). On King County's page download two files: \"Real Property Sales\" and \"Residential Building\". Then unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "json_url = 'https://data.austintexas.gov/resource/9t4d-g238.json'\n",
    "animals = pd.read_json(json_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "animals[animals['age_upon_outcome'] == '1 year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "\n",
    "### `Series.map()`\n",
    "\n",
    "The `.map()` method applies a transformation to every entry in the Series. This transformation  \"maps\" each value from the Series to a new value. A transformation can be defined by a function, Series, or dictionary - usually we'll use functions.\n",
    "\n",
    "The `.apply()` method is similar to the `.map()` method for Series, but can only use functions. It has more powerful uses when working with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_year(age):\n",
    "    if age == '1 year':\n",
    "        return '1 years'\n",
    "    else:\n",
    "        return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['age_upon_outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['new_age1'] = animals['age_upon_outcome'].map(one_year)\n",
    "animals['new_age1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Sophisticated Mapping\n",
    "\n",
    "Let's use `.map()` to turn sex_upon_outcome into a category with three values (called **ternary**): male, female, or unknown. \n",
    "\n",
    "First, explore the unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['sex_upon_outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_mapper(status):\n",
    "    if status in ['Neutered Male', 'Intact Male']:\n",
    "        return 'Male'\n",
    "    elif status in ['Spayed Female', 'Intact Female']:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['new_sex1'] = animals['sex_upon_outcome'].map(sex_mapper)\n",
    "animals.loc[:, ['sex_upon_outcome', 'new_sex1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert our ages to a common unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.loc[0, 'age_upon_outcome'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_days(age):\n",
    "    \n",
    "    '''\n",
    "    params: age upon outcome of shelter animal. \n",
    "    A number followed by a unit of time \n",
    "    'NULL', 'days', 'month', 'months', 'week', 'weeks', 'year', 'years'\n",
    "    \n",
    "    returns: days old at outcome\n",
    "    '''\n",
    "    \n",
    "    age_split = age.split(' ')\n",
    "    \n",
    "    if len(age_split) == 1:\n",
    "        return np.nan\n",
    "    \n",
    "    elif age_split[1] in ['day', 'days']:\n",
    "        return int(age_split[0])\n",
    "    \n",
    "    elif age_split[1] in ['month', 'months']:\n",
    "        return int(age_split[0]) * 30\n",
    "    \n",
    "    elif age_split[1] in ['week', 'weeks'] :\n",
    "        return int(age_split[0]) * 7\n",
    "    \n",
    "    else:\n",
    "        return int(age_split[0]) * 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['age_days'] = animals['age_upon_outcome'].map(age_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Functions\n",
    "\n",
    "Simple functions can be defined just when you need them, when you would call the function. These are called **lambda functions**. These functions are **anonymous** and disappear immediately after use.\n",
    "\n",
    "Let's use a lambda function to get rid of 'Other' in the \"animal_type' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals[animals['animal_type'] == 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['animal_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['animal_type'].map(lambda x: np.nan if x == 'Other' else x).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't modified the actual data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['animal_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "A lot of the times we'll have missing information in our data set. This can sometimes be troublesome in what we're trying to do.\n",
    "\n",
    "So far, we've been doing some preprocessing/cleaning to answer questions. Now we're going to handle the missing values in our data.\n",
    "\n",
    "There are a few strategies we can choose from and they each have their special use case.\n",
    "\n",
    "> Before making changes, it's convenient to make changes to a copy instead of overwriting data. We'll keep all our changes in `animals_clean` which will be a [copy](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html) of the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_clean = animals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill with a Relevant Value\n",
    "\n",
    "A lot of times we already have an idea of how we want to specify that a value was missing and replace it with a value that makes more sense than an \"empty\" value.\n",
    "\n",
    "For example, it might make sense to fill the value as \"MISSING\" or \"UNKNOWN\". This way it's clearer when do more analysis.\n",
    "\n",
    "> We can use Pandas' [`fillna()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) to replace missing values with something specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this creates a copy of `animals` with the missing values replaced\n",
    "animals_name_filled = animals.fillna({'name':'UNKNOWN'}) # {col_name:new_value}\n",
    "animals_name_filled[animals_name_filled['name'] == 'UNKNOWN'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `animals` DataFrame is left untouched\n",
    "animals[animals['name'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to fill missing values by specifying column(s) first\n",
    "animals_only_names = animals[['name']].fillna(value='UNKNOWN')\n",
    "animals[animals['name'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep changes in DataFrame, overwrite the column\n",
    "animals_clean[['name']] = animals_only_names\n",
    "animals_clean[animals_clean['name'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill with a Reasonable Value\n",
    "\n",
    "Other times we don't know what the missing value was but we might have a reasonable guess. This allows us to still use the data point (row) in our analysis.\n",
    "\n",
    "> Beware that filling in missing values can lead to you drawing incorrect conclusions. If most of the data from a column are missing, it's going to appear that the value you filled it in with is more common that it actually was!\n",
    "\n",
    "A lot of the time we'll use the _mean_ or _median_ for numerical values. Sometimes values like $0$ make sense since it might make sense in the context of how the data was collected.\n",
    "\n",
    "With categorical values, you might choose to fill the missing values with the most common value (the *mode*).\n",
    "\n",
    "> Similar to the previous subsection, we can use the `fillna()` method after specifying the value to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the most common value for `outcome_subtype`\n",
    "outcome_subtype_counts = animals['outcome_subtype'].value_counts()\n",
    "outcome_subtype_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets us just the values in order of most frequent to least frequent\n",
    "outcome_subtype_ordered = outcome_subtype_counts.index\n",
    "print(outcome_subtype_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first one\n",
    "most_common_outcome_subtype = outcome_subtype_ordered[0]\n",
    "\n",
    "most_common_outcome_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the built-in mode() method\n",
    "# Note this is Series so we have to get the first element (which is the value)\n",
    "most_common_outcome_subtype = animals['outcome_subtype'].mode()[0]\n",
    "most_common_outcome_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the previous subsection, we can use fillna() and update the DF\n",
    "animals_clean['outcome_subtype'] = animals['outcome_subtype']\\\n",
    ".fillna(most_common_outcome_subtype)\n",
    "animals_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify That the Data Were Missing\n",
    "\n",
    "Even after filling in missing values, it might make sense to specify that there were missing data. You can document that the data was missing by creating a new column that represents whether the data was originally missing or not.\n",
    "\n",
    "This can be helpful when you suspect that the fact the data was missing could be important for an analysis.\n",
    "\n",
    "> Since we already removed some missing values, we're going to reference back to the original `animals` DataFrame. (Good thing we didn't overwrite it! 😉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's specify which values were originally missing in \"outcome_subtype\"\n",
    "missing_outcome_subtypes = animals['outcome_subtype'].isna()\n",
    "missing_outcome_subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for missing outcome subtypes matched w/ replaced values\n",
    "animals_clean['outcome_subtype_missing'] = missing_outcome_subtypes\n",
    "animals_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Missing Data\n",
    "\n",
    "You should try to keep as much relevant data as possible, but sometimes the other methods don't make as much sense and it's better to remove or **drop** the missing data.\n",
    "\n",
    "We typically drop missing data if very little data would be lost and/or trying to fill in the values wouldn't make sense for our use case. For example, if you're trying to predict the outcome based on the other features/columns it might not make sense to fill in those missing values with something you can't confirm.\n",
    "\n",
    "> We noticed that `outcome_type` had only a few missing values. It might not be worth trying to handle those few missing values. We can pretend that the `outcome_type` was an important feature and without it the rest of the row's data is of little importance to us.\n",
    ">\n",
    "> So we'll decide to drop the row if a value from `outcome_type` is missing. We'll use Pandas' [`dropna()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will drop any row (axis=0) or column (axis=1) that has missing values\n",
    "animals_clean = animals_clean.dropna(   # Note we're overwriting animals_clean\n",
    "                                axis=0, # This is the default & will drop rows;\n",
    "                                        # axis=1 for cols\n",
    "                                subset=['outcome_type'] # Specific labels\n",
    "                                                        # to consider (defaults to \"all\")\n",
    ")\n",
    "animals_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Before and After\n",
    "\n",
    "We can now see all the work we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "animals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data cleaned\n",
    "animals_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_clean.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating over DataFrames: `.groupby()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those of you familiar with SQL have probably used the GROUP BY command. (And if you haven't, you'll see it very soon!) Pandas has this, too.\n",
    "\n",
    "The `.groupby()` method is especially useful for aggregate functions applied to the data grouped in particular ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.groupby('animal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group by multiple columns, and also return a DataFrameGroupBy object\n",
    "\n",
    "Notice the object type [DataFrameGroupBy](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.groups` and `.get_group()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This retuns each group indexed by the group name:\n",
    "# e.g. 'Bird', along with the row indices of each value\n",
    "animals.groupby('animal_type').groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we know we are working with a type of object, it opens up a suite of attributes and methods. One attribute we can look at is groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we know the group indices, we can return the groups using those indices.\n",
    "animals.groupby('animal_type').get_group('Dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same goes for multi index groupbys\n",
    "animal_outcome = animals.groupby(['animal_type', 'outcome_type'])\n",
    "animal_outcome.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal_outcome.groups is a dictionary, so we can access the group names using keys()\n",
    "animal_outcome.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then get a specific group, such as Cats that were adopted\n",
    "animal_outcome.get_group(('Cat', 'Adoption'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, as we will see in SQL, groupby objects are intended to be used with aggregation. In SQL, we will see that our queries that include GROUP BY require aggregation performed on columns.\n",
    "\n",
    "We can use `.sum()`, `.mean()`, `.count()`, `.max()`, `.min()`, etc. Find a list of common aggregations [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.groupby('animal_type').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use `.groupby()` to find the most recently born of each (main) animal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    <code>animals.groupby('animal_type')['date_of_birth'].max()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Level Up: Pivoting a DataFrame\n",
    "\n",
    "### `.pivot_table()`\n",
    "\n",
    "Those of you familiar with Excel have probably used Pivot Tables. Pandas has a similar functionality.\n",
    "\n",
    "Grouping by two different columns can be very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "animals.groupby(by=['outcome_type', 'sex_upon_outcome']).agg(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But it has the unsavory side effect of creating a two-level index. This can be a good time to use `.pivot_table()`.\n",
    "\n",
    "(There is also a `.pivot()`. For the somewhat subtle differences, see [here](https://stackoverflow.com/questions/30960338/pandas-difference-between-pivot-and-pivot-table-why-is-only-pivot-table-workin).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sex\": [\"male\", \"male\", \"male\", \"male\", \"male\",\n",
    "                          \"female\", \"female\", \"female\", \"female\"],\n",
    "                    \"num_puppies\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                          \"one\", \"one\", \"two\", \"two\"],\n",
    "                    \"breed\": [\"terrier\", \"retriever\", \"retriever\", \"terrier\",\n",
    "                          \"terrier\", \"retriever\", \"terrier\", \"terrier\",\n",
    "                          \"retriever\"],\n",
    "                    \"past_owners\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                    \"family_members\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This first example aggregates values by taking the sum.\n",
    "\n",
    "table = pd.pivot_table(df, values='past_owners', index=['sex', 'num_puppies'],\n",
    "                     columns=['breed'], aggfunc=np.sum)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Back to Austin animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "animals.pivot_table(index='outcome_type', columns='sex_upon_outcome', aggfunc=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Use `.pivot_table()` to add up the number of my tasks by category. Hint: Use `sum()` as your aggregating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tasks = pd.DataFrame({'category': ['house', 'house', 'school', 'school'],\n",
    "                      'descr': ['kitchen', 'laundry', 'git', 'Python'],\n",
    "                      'priority': [2, 3, 4, 1], 'num_tasks': [2, 1, 2, 3]})\n",
    "\n",
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    <code>tasks.pivot_table(values='num_tasks', index='category', aggfunc=sum)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Level Up: Methods for Combining DataFrames: `.join()`, `.merge()`, `pd.concat()`\n",
    "\n",
    "### `.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy1 = pd.DataFrame([[63, 142], [33, 47]], columns=['age', 'HP'])\n",
    "toy2 = pd.DataFrame([[63, 100], [33, 200]], columns=['age', 'MP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can't just join these as they are, since we haven't specified our suffixes.\n",
    "\n",
    "toy1.join(toy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy1.join(toy2, lsuffix='1', rsuffix='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we don't want to keep both, we could set the overlapping column as the index in each DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy1.set_index('age').join(toy2.set_index('age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more on this method, check out the [doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### `.merge()`\n",
    "\n",
    "Or we could use `.merge()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toy1.merge(toy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_chars = pd.read_csv('data/ds_chars.csv', index_col=0)\n",
    "ds_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "states = pd.read_csv('data/states.csv', index_col=0)\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The `how` Parameter\n",
    "\n",
    "This parameter in both `.join()` and `.merge()` tells the compiler what sort of join to effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_chars.merge(states,\n",
    "               left_on='home_state',\n",
    "               right_on='state',\n",
    "               how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_chars.merge(states,\n",
    "               left_on='home_state',\n",
    "               right_on='state',\n",
    "               how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `pd.concat()`\n",
    "\n",
    "This method takes a *list* of pandas objects as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_full = pd.concat([ds_chars, states])\n",
    "ds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`pd.concat()`–– and many other pandas operations –– make use of an `axis` parameter. For this particular method I need to specify whether I want to concatenate the DataFrames *row-wise* (`axis=0`) or *column-wise* (`axis=1`). The default is `axis=0`, so let's override that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_full = pd.concat([ds_chars, states], axis=1)\n",
    "ds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## King County Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scientists, we want to build a model to predict the sale price of a house in Seattle in 2019, based on its square footage. We know that the King County Department of Assessments has comprehensive data available on real property sales in the Seattle area. We need to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You'll need to use a new encoding here. List of all encodings here:\n",
    "# https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "\n",
    "# Both of these csv files have many columns, so we'll just pre-select\n",
    "# which ones we want to use.\n",
    "\n",
    "sales_df = pd.read_csv('/Users/gdamico/Downloads/EXTR_RPSale.csv',\n",
    "                       encoding='latin-1',\n",
    "                       usecols=['Major', 'Minor', 'DocumentDate', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df = pd.read_csv('~/Downloads/EXTR_ResBldg.csv',\n",
    "                     usecols=['Major', 'Minor', 'SqFtTotLiving', 'ZipCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Level Up sections for more on merging!\n",
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that we're missing ZIP codes for many of the sales transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data[sales_data['ZipCode'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exercises\n",
    "Important: Do these *in order*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. What percentage of housing records are missing ZIP codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    <code>sales_data['ZipCode'].isna().sum() / sales_data.shape[0]</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's drop the rows with missing zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales_data = sales_data.loc[~sales_data['ZipCode'].isna(), :]\n",
    "\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2. Investigate and drop rows with invalid values in the SalePrice and SqFtTotLiving columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>One possible answer here</summary>\n",
    "    <code>sales_data = sales_data[sales_data['SalePrice'] > 10000]</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3. Investigate and handle non-numeric ZipCode values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Can you find a way to shorten ZIP+4 codes to the first five digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_integer(x):\n",
    "    try:\n",
    "        _ = int(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "sales_data.loc[sales_data['ZipCode'].apply(is_integer) == False, 'ZipCode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>One possible answer here</summary>\n",
    "    <code>def five_digit_ZIP(x):\n",
    "    try:\n",
    "        return int(str(x)[:5])\n",
    "    except:\n",
    "        return x\n",
    "sales_data['ZipCode'] = sales_data['ZipCode'].map(five_digit_ZIP)\n",
    "sales_data = sales_data.loc[sales_data['ZipCode'].apply(is_integer) == True, :]\n",
    "sales_data['ZipCode'] = sales_data['ZipCode'].map(int)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4. Add a column for PricePerSqFt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['PricePerSqFt'] = sales_data['SalePrice'] / sales_data['SqFtTotLiving']</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5. Subset the data to 2021 sales only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can assume that the DocumentDate is approximately the sale date. The first thing you should do is convert the date to a datetime object with the following code:\n",
    "\n",
    "<code>sales_data['DocumentDate'] = pd.to_datetime(sales_data['DocumentDate'])</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['DocumentDate'] = pd.to_datetime(sales_data['DocumentDate'])\n",
    "sales_data = sales_data.loc[sales_data['DocumentDate'] > '12/31/2020']</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "6. What is the mean price per square foot for a house sold in Seattle in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['PricePerSqFt'].mean()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "7. I'm interested in seeing all the Major ID nos. that cover multiple ZIP codes. The first step will be to:\n",
    "\n",
    "- group by 'Major' and then check out the ZIP codes for each 'Major' value. Let's store that in a new variable called \"grouped\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>grouped = sales_data.groupby('Major')['ZipCode'].value_counts()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8. Then I'll need to:\n",
    "\n",
    "- iterate over that Series, looking for entries where the first half of the index (the 'Major' ID) corresponds to two different \"second halves\" of the index (the 'ZipCode'). One way to proceed would be to initialize an empty list, and then add elements of the index to it when the 'Major' value of an entry matches the 'Major' value of the next entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "<code>multiples = []\n",
    "for j in range(len(grouped) - 1):\n",
    "    if grouped.index[j+1][0] == grouped.index[j][0]:\n",
    "        multiples.append(grouped.index[j])\n",
    "        multiples.append(grouped.index[j+1])</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "9. Which ZIP Code has had the most sales in 2021, and how many has it had?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data.groupby('ZipCode').count().sort_values(by='Major', ascending=False).head(1)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "10. Looking ahead: Plotting!\n",
    "\n",
    "a. What happens if we run:\n",
    "\n",
    "<code>sales_data['SqFtTotLiving'].hist();</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "b. What about:\n",
    "\n",
    "<code>sales_data_sorted = sales_data.sort_values('SqFtTotLiving')\n",
    "sales_data_sorted.plot(x='SqFtTotLiving', y='SalePrice');</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "c. How could we plot the number of sales by date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>ctr = sales_data.groupby('DocumentDate').count().reset_index()\n",
    "ctr.plot(x='DocumentDate', y='SalePrice') # _Any_ column will work here for the  y-value!;</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
